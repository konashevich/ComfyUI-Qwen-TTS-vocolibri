S C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS> C:/Users/akona/OneDrive/Dev/ComfyUI-Qwen-TTS/.venv/Scripts/python.exe scripts/paper_to_audio.py "c:\Users\akona\OneDrive\Dev\Public-VS-Private\Ledger Journal\Ledger-LaTeX-Template-OTH\Debunking_Blockchain_TTS.md" --output_dir "output\Debunking_Blockchain_Male_0.6B_batch" --voice Ryan --model_path "models\qwen-tts\Qwen3-TTS-12Hz-0.6B-CustomVoice" --attn_impl sdpa --disable_flash_sdp --disable_mem_efficient_sdp --force_math_sdp --dtype bfloat16 --deterministic --seed 1234 --do_sample false --top_k 0 --top_p 1.0 --temperature 1.0 --repetition_penalty 1.0 --batch_size 16 --max_batch_chars 6000
2026-02-04 13:43:33,283 - INFO - Using model: models\qwen-tts\Qwen3-TTS-12Hz-0.6B-CustomVoice
2026-02-04 13:43:33,284 - INFO - Device: cuda
2026-02-04 13:43:33,300 - INFO - Cleaning text...
2026-02-04 13:43:33,304 - INFO - Split text into chunks...
2026-02-04 13:43:33,306 - INFO - Total chunks: 192
2026-02-04 13:43:33,306 - INFO - Loading Qwen-TTS model...
`torch_dtype` is deprecated! Use `dtype` instead!
2026-02-04 13:43:33,325 - INFO - speaker_encoder_config is None. Initializing talker model with default values
2026-02-04 13:43:33,326 - INFO - talker_config is None. Initializing talker model with default values
2026-02-04 13:43:33,327 - INFO - speaker_encoder_config is None. Initializing talker model with default values
2026-02-04 13:43:33,327 - INFO - code_predictor_config is None. Initializing code_predictor model with default values
2026-02-04 13:43:33,328 - INFO - code_predictor_config is None. Initializing code_predictor model with default values
2026-02-04 13:43:35,910 - INFO - encoder_config is None. Initializing encoder with default values
2026-02-04 13:43:35,910 - INFO - decoder_config is None. Initializing decoder with default values
2026-02-04 13:43:38,012 - INFO - Available speakers: ['serena', 'vivian', 'uncle_fu', 'ryan', 'aiden', 'ono_anna', 'sohee', 'eric', 'dylan']
2026-02-04 13:43:38,014 - INFO - Starting generation...
2026-02-04 13:43:38,015 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 13:43:38,412 - INFO - code_predictor_config is None. Initializing code_predictor model with default values
The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\qwen_tts\core\models\modeling_qwen3_tts.py:1776: UserWarning: cumsum_cuda_kernel does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:95.)
  position_ids = attention_mask.float().cumsum(-1) - 1
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\qwen_tts\core\models\modeling_qwen3_tts.py:527: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:208.)
  freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(2, 3)
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\.venv\Lib\site-packages\torch\nn\modules\linear.py:125: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:208.)
  return F.linear(input, self.weight, self.bias)
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\.venv\Lib\site-packages\transformers\integrations\sdpa_attention.py:96: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:208.)
  attn_output = torch.nn.functional.scaled_dot_product_attention(
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\qwen_tts\core\models\modeling_qwen3_tts.py:569: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:208.)
  freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)