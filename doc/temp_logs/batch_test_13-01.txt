PS C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS> C:/Users/akona/OneDrive/Dev/ComfyUI-Qwen-TTS/.venv/Scripts/python.exe scripts/paper_to_audio.py "c:\Users\akona\OneDrive\Dev\Public-VS-Private\Ledger Journal\Ledger-LaTeX-Template-OTH\Debunking_Blockchain_TTS.md" --output_dir "output\Debunking_Blockchain_Male_0.6B_batch" --voice Ryan --model_path "models\qwen-tts\Qwen3-TTS-12Hz-0.6B-CustomVoice" --attn_impl sdpa --disable_flash_sdp --disable_mem_efficient_sdp --force_math_sdp --dtype bfloat16 --deterministic --seed 1234 --do_sample false --top_k 0 --top_p 1.0 --temperature 1.0 --repetition_penalty 1.0 --batch_size 16 --max_batch_chars 6000
2026-02-04 09:04:12,763 - INFO - Using model: models\qwen-tts\Qwen3-TTS-12Hz-0.6B-CustomVoice
2026-02-04 09:04:12,763 - INFO - Device: cuda
2026-02-04 09:04:12,764 - INFO - Cleaning text...
2026-02-04 09:04:12,767 - INFO - Split text into chunks...
2026-02-04 09:04:12,767 - INFO - Total chunks: 192
2026-02-04 09:04:12,768 - INFO - Loading Qwen-TTS model...
`torch_dtype` is deprecated! Use `dtype` instead!
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,541 - INFO - code_predictor_config is None. Initializing code_predictor model with default values
The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\qwen_tts\core\models\modeling_qwen3_tts.py:1776: UserWarning: cumsum_cuda_kernel does not have a deterministic implementation, but you set '2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,541 - INFO - code_predictor_config is None. Initializing code_predictor model with default values
The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\qwen_tts\core\models\modeling_qwen3_tts.py:1776: UserWarning: cumsum_cuda_kernel does not have a deterministic implementation, but you set '2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,541 - INFO - code_predictor_config is None. Initializing code_predictor model with default values
The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,541 - INFO - code_predictor_config is None. Initializing code_predictor model with default values
The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\qwen_tts\core\models\modeling_qwen3_tts.py:1776: UserWarning: cumsum_cuda_kernel does not have a deterministic implementat2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,360 - INFO - Generating batch of 11 chunks (remaining: 16)...
2026-02-04 09:04:16,541 - INFO - code_predictor_config is None. Initializing code_predictor model with default values
The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\qwen_tts\core\models\modeling_qwen3_tts.py:1776: UserWarning: cumsum_cuda_kernel does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:95.)
  position_ids = attention_mask.float().cumsum(-1) - 1
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\qwen_tts\core\models\modeling_qwen3_tts.py:527: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:208.)
  freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(2, 3)
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\.venv\Lib\site-packages\torch\nn\modules\linear.py:125: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:208.)
  return F.linear(input, self.weight, self.bias)
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\.venv\Lib\site-packages\transformers\integrations\sdpa_attention.py:96: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:208.)
  attn_output = torch.nn.functional.scaled_dot_product_attention(
C:\Users\akona\OneDrive\Dev\ComfyUI-Qwen-TTS\qwen_tts\core\models\modeling_qwen3_tts.py:569: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\Context.cpp:208.)
  freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
